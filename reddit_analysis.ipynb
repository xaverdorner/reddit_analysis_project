{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/opt/anaconda3/envs/reddit/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import time\n",
    "import praw\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id=config.CLIENT_ID, \\\n",
    "                     client_secret=config.CLIENT_SECRET, \\\n",
    "                     user_agent=config.USER_AGENT, \\\n",
    "                     username=config.USERNAME, \\\n",
    "                     password=config.PASSWORD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility functions: dataframes, time converter and timestamper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to dataframe for better readability\n",
    "\n",
    "def dict_to_frame(red_dict):\n",
    "    \"\"\"takes a dictionary with a 'created' key and\n",
    "    outpurs a datagframe with human readable time\"\"\"\n",
    "    frame = pd.DataFrame(red_dict)\n",
    "    if 'created' in red_dict:\n",
    "        frame['created'] = frame['created'].apply(get_date)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that adds a timestamp to a string\n",
    "def timestamper():\n",
    "    \"\"\"returns a string of a timestamp: year, month, day\"\"\"\n",
    "    timestamp = dt.datetime.now()\n",
    "    return str(dt.date(timestamp.year, timestamp.month, timestamp.day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(created):\n",
    "    \"\"\"takes a unix timestamp and converts it to date time\"\"\"\n",
    "    return dt.datetime.fromtimestamp(created)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Author analysis: all subreddit authors, most popular authors, author details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# author comment extraction function \n",
    "\n",
    "def author_comments(author):\n",
    "    \"\"\"takes a reddit user name and \n",
    "    returns a dataframe of the 'new' the author's comments with score and creation date\"\"\"\n",
    "    author_dict = {\"body\":[], \"score\":[], \"created\": []}\n",
    "    for comment in reddit.redditor(author).comments.new(limit=None):\n",
    "        author_dict['body'].append(comment.body),\n",
    "        author_dict['score'].append(comment.score),\n",
    "        author_dict['created'].append(comment.created)\n",
    "    author_frame = pd.DataFrame(author_dict)\n",
    "    author_frame['created'] = author_frame['created'].apply(get_date)\n",
    "    return author_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting all commentors of a 100 submission subset of a subreddit and their scores \n",
    "\n",
    "def subreddit_authors(data_frame):\n",
    "    \"\"\"takes a dataframe of submissions (needs 'id') in a subreddit, iterates over all comments in all submission,\n",
    "    outputs a dataframe of authors and their number of comment & their accumulated score\"\"\"\n",
    "    author_dict = {}\n",
    "    # iterating over all submission in a subreddit dataframe\n",
    "    for sub in data_frame['id']:\n",
    "        submission = reddit.submission(sub)\n",
    "        # iterating over all comments within a submission \n",
    "        submission.comments.replace_more(limit=None)\n",
    "        for comment in submission.comments.list():\n",
    "            if str(comment.author) in author_dict.keys():\n",
    "                author_dict[str(comment.author)][0] += 1\n",
    "                author_dict[str(comment.author)][1] += comment.score\n",
    "            else:\n",
    "                # creating a first entry if the author is not yet in the dict\n",
    "                author_dict[str(comment.author)] = [1, comment.score]\n",
    "    author_frame = pd.DataFrame(author_dict, index=['num_comments', 'sum_karma']).transpose()\n",
    "    return author_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to scrape the detailed data of the top 25 weekly redditors \n",
    "\n",
    "def top_redditor_scraper(redditor_list):\n",
    "    \"\"\"Takes a list of usernames and outputs\n",
    "    a dictionary with author key and cake day, link and comment karma\"\"\"\n",
    "    detail_dict = {}\n",
    "    for author in redditor_list.index[:25]:\n",
    "        try:\n",
    "            created = get_date(reddit.redditor(author).created)\n",
    "            link_karma = reddit.redditor(author).link_karma \n",
    "            comment_karma = reddit.redditor(author).comment_karma\n",
    "            detail_dict[author] = [created, link_karma, comment_karma]\n",
    "        except:\n",
    "            detail_dict[author] = [None, None, None]\n",
    "    detail_frame = pd.DataFrame(detail_dict, index=['created', 'link_karma', 'comment_karma'])\n",
    "    return detail_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subreddit & submission analysis: most popular submissions, all comments from an author "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subreddit_submissions(subreddit):\n",
    "    \"\"\"takes a subreddit and outputs a\n",
    "    dataframe with the 100 hottest posts\"\"\"\n",
    "    topics_dict = {\"title\":[], \"author\": [], \"score\":[], \"id\":[], \"url\":[], \"comms_num\": [], \\\n",
    "                \"created\": [], \"body\":[]}\n",
    "    for submission in subreddit.hot(limit=100):\n",
    "        topics_dict[\"title\"].append(submission.title)\n",
    "        topics_dict[\"author\"].append(submission.author)\n",
    "        topics_dict[\"score\"].append(submission.score)\n",
    "        topics_dict[\"id\"].append(submission.id)\n",
    "        topics_dict[\"url\"].append(submission.url)\n",
    "        topics_dict[\"comms_num\"].append(submission.num_comments)\n",
    "        topics_dict[\"created\"].append(submission.created)\n",
    "        topics_dict[\"body\"].append(submission.selftext)\n",
    "    topic_frame = pd.DataFrame(topics_dict)\n",
    "    return topic_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function that collects all comments from a submission\n",
    "\n",
    "def submission_comments(submission):\n",
    "    \"\"\"takes a submission (reddit.submission) and outputs\n",
    "    a dataframe of all comments in that submission\"\"\"\n",
    "    comment_dict = {\"body\":[], \"score\":[], \"author\":[], \"created\": []}\n",
    "    submission.comments.replace_more(limit=None)\n",
    "    for comment in submission.comments.list():\n",
    "        comment_dict['body'].append(comment.body),\n",
    "        comment_dict['score'].append(comment.score),\n",
    "        comment_dict['author'].append(comment.author),\n",
    "        comment_dict['created'].append(comment.created)\n",
    "    comment_frame = pd.DataFrame(comment_dict)\n",
    "    comment_frame['created'] = comment_frame['created'].apply(get_date)\n",
    "    comment_frame['author'] = comment_frame['author'].apply(lambda x: x.name)\n",
    "    return comment_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_sub = reddit.subreddit('de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4277, 264878)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_sub.accounts_active, de_sub.subscribers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### r/dataisbeautiful analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_redditor = reddit.redditor('DukeMactavish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get individual submission \n",
    "\n",
    "data_discussion_post = reddit.submission('gdbaiz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all comments in a submission\n",
    "\n",
    "discussion_comments = submission_comments(data_discussion_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "discussion_comments['author'] = discussion_comments['author'].apply(lambda x: x.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author\n",
       "2134123412341234      1\n",
       "pierre_x10            1\n",
       "jtg123g               1\n",
       "ilikemusicandgame     1\n",
       "gints                 1\n",
       "flurbius              1\n",
       "fast_edo              1\n",
       "dummy_thiqq           1\n",
       "alsocomfy             1\n",
       "Zarricaron            1\n",
       "TradingToni           1\n",
       "vikram201112018       1\n",
       "TheNajeeb             1\n",
       "Prudent-Gain101       1\n",
       "Mildly_Upset_Toast    1\n",
       "Halstrop              1\n",
       "Electric_sheeples     1\n",
       "DukeMactavish         1\n",
       "Brittle_Panda         1\n",
       "Azzozs                1\n",
       "AVLien                1\n",
       "yeuxwbbw              1\n",
       "DinosaurAssassin      2\n",
       "Barnst                2\n",
       "ranginpanda           2\n",
       "Puppies4Lovies        2\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discussion_comments.groupby('author')['author'].count().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the subreddit\n",
    "\n",
    "beautidata = reddit.subreddit('dataisbeautiful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step one: get all hot & all new submissions\n",
    "\n",
    "hot_submissions = subreddit_submissions(beautidata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrinting a dataframe to disk\n",
    "#hot_submissions.to_csv(f'top100_beautifuldata_{timestamper()}.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing dataframes of 2 consecutive days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the dataframes \n",
    "\n",
    "hot_10may = pd.read_csv('top100_beautifuldata_2020-05-09.csv', index_col=0)\n",
    "hot_9may = pd.read_csv('top100_beautifuldata_2020-05-10.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the most popular redditors in r/dataisbeautiful hot posts \n",
    "\n",
    "top_data_authors = subreddit_authors(hot_10may)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_negative = top_data_authors.sort_values(by='sum_karma')\n",
    "most_positive = top_data_authors.sort_values(by='sum_karma', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_comments</th>\n",
       "      <th>sum_karma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sv_gravlty</th>\n",
       "      <td>2</td>\n",
       "      <td>-82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bitch6</th>\n",
       "      <td>2</td>\n",
       "      <td>-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bscottlove</th>\n",
       "      <td>3</td>\n",
       "      <td>-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GetPucked14</th>\n",
       "      <td>2</td>\n",
       "      <td>-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElectricShock</th>\n",
       "      <td>2</td>\n",
       "      <td>-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPAnalyst</th>\n",
       "      <td>27</td>\n",
       "      <td>1964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipflop</th>\n",
       "      <td>2</td>\n",
       "      <td>2152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>steevie265</th>\n",
       "      <td>1</td>\n",
       "      <td>2992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strumthebuilding</th>\n",
       "      <td>1</td>\n",
       "      <td>3446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zkgkilla</th>\n",
       "      <td>3</td>\n",
       "      <td>3706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4086 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  num_comments  sum_karma\n",
       "Sv_gravlty                   2        -82\n",
       "bitch6                       2        -28\n",
       "bscottlove                   3        -27\n",
       "GetPucked14                  2        -25\n",
       "ElectricShock                2        -22\n",
       "...                        ...        ...\n",
       "JPAnalyst                   27       1964\n",
       "zipflop                      2       2152\n",
       "steevie265                   1       2992\n",
       "strumthebuilding             1       3446\n",
       "zkgkilla                     3       3706\n",
       "\n",
       "[4086 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_data_authors.to_csv(f'top100_top_redditors_{timestamper()}.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_frame = top_redditor_scraper(most_negative)\n",
    "positive_frame = top_redditor_scraper(most_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_redditors = pd.DataFrame(negative_frame, index=['created', 'link_karma', 'comment_karma']).transpose()\n",
    "positive_redditors = pd.DataFrame(positive_frame, index=['created', 'link_karma', 'comment_karma']).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created</th>\n",
       "      <th>link_karma</th>\n",
       "      <th>comment_karma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zkgkilla</th>\n",
       "      <td>2016-01-18 06:50:34</td>\n",
       "      <td>4377</td>\n",
       "      <td>9819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strumthebuilding</th>\n",
       "      <td>2012-10-13 17:40:00</td>\n",
       "      <td>218</td>\n",
       "      <td>6675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>steevie265</th>\n",
       "      <td>2018-07-11 05:40:43</td>\n",
       "      <td>38</td>\n",
       "      <td>3145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipflop</th>\n",
       "      <td>2013-02-12 11:51:37</td>\n",
       "      <td>12676</td>\n",
       "      <td>25675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPAnalyst</th>\n",
       "      <td>2018-02-15 04:56:39</td>\n",
       "      <td>27007</td>\n",
       "      <td>35139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             created link_karma comment_karma\n",
       "zkgkilla         2016-01-18 06:50:34       4377          9819\n",
       "strumthebuilding 2012-10-13 17:40:00        218          6675\n",
       "steevie265       2018-07-11 05:40:43         38          3145\n",
       "zipflop          2013-02-12 11:51:37      12676         25675\n",
       "JPAnalyst        2018-02-15 04:56:39      27007         35139"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_redditors.head()\n",
    "#positive_redditors.to_csv(f'positive_redditors_{timestamper()}.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created</th>\n",
       "      <th>link_karma</th>\n",
       "      <th>comment_karma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sv_gravlty</th>\n",
       "      <td>2019-04-19 09:27:39</td>\n",
       "      <td>1</td>\n",
       "      <td>1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bitch6</th>\n",
       "      <td>2015-02-16 10:01:33</td>\n",
       "      <td>7</td>\n",
       "      <td>8108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bscottlove</th>\n",
       "      <td>2015-03-09 21:29:00</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GetPucked14</th>\n",
       "      <td>2017-01-30 10:23:24</td>\n",
       "      <td>33</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElectricShock</th>\n",
       "      <td>2011-01-08 13:03:59</td>\n",
       "      <td>81</td>\n",
       "      <td>4799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          created link_karma comment_karma\n",
       "Sv_gravlty    2019-04-19 09:27:39          1          1009\n",
       "bitch6        2015-02-16 10:01:33          7          8108\n",
       "bscottlove    2015-03-09 21:29:00          1            40\n",
       "GetPucked14   2017-01-30 10:23:24         33           125\n",
       "ElectricShock 2011-01-08 13:03:59         81          4799"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_redditors.head()\n",
    "#negative_redditors.to_csv(f'negative_redditors_{timestamper()}.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
